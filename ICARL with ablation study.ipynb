{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ICARL with ablation study.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X9pJaGMHvUTf","colab_type":"text"},"source":["**MODULES**"]},{"cell_type":"code","metadata":{"id":"HpCwBfycvTB5","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import BCEWithLogitsLoss\n","from torch.nn import MSELoss\n","from torch.nn import CrossEntropyLoss\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","from torchvision.datasets import CIFAR100\n","import torch.optim as optim\n","\n","\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import random\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_-0s4GMitVt","colab_type":"text"},"source":["**ICIFAR100**"]},{"cell_type":"code","metadata":{"id":"LhEvvapHQW62","colab_type":"code","colab":{}},"source":["class iCIFAR10(CIFAR10):\n","  def __init__(self, root,classes,train,transform=None,target_transform=None,download=False):\n","    super(iCIFAR10, self).__init__(root,train=train,transform=transform,target_transform=target_transform,download=download)\n","    \n","    train_data = []\n","    train_labels = []\n","\n","    for i in range(len(self.data)):\n","      if self.targets[i] in classes:\n","        train_data.append(self.data[i])\n","        train_labels.append(self.targets[i])\n","\n","    self.data = np.array(train_data)\n","    self.targets = train_labels\n","  \n","  def __getitem__(self, index):\n","    img, target = self.data[index], self.targets[index]\n","    img = Image.fromarray(img)\n","    \n","    if self.transform is not None:\n","      img = self.transform(img)\n","    \n","    if self.target_transform is not None:\n","      target = self.target_transform(target)\n","    \n","    return index, img, target\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def get_image_class(self, label):\n","    return self.data[np.array(self.targets) == label]\n","\n","  def append(self, images, labels):\n","    self.data = np.concatenate((self.data, images), axis=0)\n","    \n","    self.targets = self.targets + labels\n","\n","class iCIFAR100(iCIFAR10):\n","    base_folder = 'cifar-100-python'\n","    url = \"http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n","    filename = \"cifar-100-python.tar.gz\"\n","    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n","    train_list = [\n","        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n","    ]\n","    test_list = [\n","        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n","    ]\n","    meta = {\n","        'filename': 'meta',\n","        'key': 'fine_label_names',\n","        'md5': '7973b15100ade9c7d40fb424638fde48',\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QAC9q4Sr4zfI","colab_type":"text"},"source":["**MODEL**"]},{"cell_type":"code","metadata":{"id":"zKkdgE9sitA6","colab_type":"code","colab":{}},"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=0): #SAREBBE num_classes=10\n","        self.inplanes = 16\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_layer(block, 16, layers[0])\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        self.fc = nn.Linear(64 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, toExtract):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        if toExtract==True:\n","          return x\n","        else:\n","          x = self.fc(x)\n","          return x\n","\n","def resnet32(pretrained=False, **kwargs):\n","    n = 5\n","    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38vFYaZtoNIQ","colab_type":"text"},"source":["**Set Argument**"]},{"cell_type":"code","metadata":{"id":"wHjF3m9On4J5","colab_type":"code","colab":{}},"source":["DEVICE = 'cuda'    \n","BATCH_SIZE = 128\n","# LR = 2         \n","NUM_EPOCHS = 70\n","MILESTONE=[49,63]\n","WEIGHT_DECAY = 0.00001\n","MOMENTUM=0.9 \n","GAMMA = 0.2\n","K = 2000 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_NQKsDRlAiV","colab_type":"code","colab":{}},"source":["class iCaRLNet(nn.Module):\n","  # def __init__(self, n_classes):\n","  def __init__(self, loss_variant=\"standard\",classifier_variant=\"standard\"):\n","    super(iCaRLNet, self).__init__()\n","    self.net = resnet32()                 #net given\n","    self.n_classes = 0                    #total number of classes up to now \n","    self.classes_known=[]                 #list of all classes seen up to now\n","    self.new_classes=[]                   #list new classes at every step\n","    self.dic={}                           #dictionary used to map class label from 0 to n_classes according to the order of classes\n","    self.count_per_dic=0                  #to count the number of element in the dictionary\n","    self.exemplar_sets = []               #list where elements are lists containg all the examplar of that class (saved as numpy array)        \n","    self.exemplar_sets_labels=[]          #list to know the label of exemplars\n","    self.all_labels=[]                    #list of all labels seen up to now                    \n","    self.compute_means = True             #flag to compute the mean only once during the classification\n","    self.exemplar_means = []              #list containg the mean of each exemplars' class\n","    self.loss_variant = loss_variant      #variant for the loss\n","    if self.loss_variant == \"bce_ce\" or self.loss_variant==\"L2_L2\":\n","      self.LR = 0.2\n","    else:\n","      self.LR = 2\n","    self.classifier_variant=classifier_variant\n","    self.classifier=None\n","    self.scaler=StandardScaler()\n","\n","\n","    \n","  def forward(self, x, toExtract=False):  #toExtract=True -> gives the features (results of convolutional layers), toExtract=False -> gives the output of the fully connected\n","    x = self.net(x, toExtract)\n","    return x\n","\n","  def classify_standard(self, x, train_set,transform):\n","    self.net.train(False) #no training anymore\n","    with torch.no_grad():\n","      batch_size = x.size(0) #128, batch_size\n","      if self.compute_means:  #computing mean only once, at the first iteration\n","        print(\"Now the means are computed\")\n","        exemplar_means = []\n","        count=-1\n","        for P_y in self.exemplar_sets:  #P_y are all the exemplars of class y\n","          count+=1\n","          features = []\n","          classe_giusta=self.exemplar_sets_labels[count] #take the original class (from the mapped to the real one)\n","          if classe_giusta not in self.new_classes: #if the image is old,it's taken from the exemplars set\n","            for ex in P_y:\n","              ex = transform(Image.fromarray(ex)).cuda()\n","              feature = self.net(ex.unsqueeze(0),True)\n","              feature = feature.squeeze()\n","              feature.data = feature.data/ feature.data.norm() # normalization\n","              features.append(feature)\n","          if classe_giusta in self.new_classes: #if the image is new, it's taken from the train set\n","            img_classes=train_set.get_image_class(classe_giusta)\n","            for immagine in img_classes:\n","              im = transform(Image.fromarray(immagine)).cuda()\n","              feature = self.net(im.unsqueeze(0),True)\n","              feature = feature.squeeze()\n","              feature.data = feature.data/ feature.data.norm() # normalization\n","              features.append(feature)\n","          features = torch.stack(features) #stack features of exemplars and images from train all together \n","          mu_y = features.mean(0).squeeze() #mean of the class y\n","          mu_y.data = mu_y.data / mu_y.data.norm() # normalization\n","          exemplar_means.append(mu_y) #saving mean\n","        self.exemplar_means = exemplar_means\n","        self.compute_means = False #to not compute again within the same loader (will be set to true in update_representation) \n","        print (\"Finish\")\n","        \n","      exemplar_means = self.exemplar_means #to retrieve the value computed at the first iteration on the loader\n","      means = torch.stack(exemplar_means)   #[10,64] becomes an unique tensor with 10 elements (length=64), then 20,.....\n","\n","      means = torch.stack([means] * batch_size) #torch.Size([128, 10, 64]) [batch_size,n_classes,feature_size]\n","\n","      means = means.transpose(1, 2)  #torch.Size([128, 64, 10]) [batch_size,feature_size,n_classes]\n","      \n","      feature = self.net(x,True)  # feature representation is extracted for the images x that have to be classified (tensor[128,64])\n","      for i in range(feature.size(0)): #for each image in the batch\n","        feature.data[i] = feature.data[i] / feature.data[i].norm() #feature.data[i] it's a tensor 64 (feature representation of image i)\n","      feature = feature.unsqueeze(2) #from [128,64] to [128,64,1]\n","      feature = feature.expand_as(means) #[128,64,10]\n","\n","      dists = (feature - means).pow(2).sum(1).squeeze()    #[128,10] [batch_size,n_classes]\n","      _, preds = dists.min(1) #index which corresponds to the minimum distance (from 0 to 9 for the first 10 classes)    \n","    \n","      listMap=[]\n","      for el in preds:\n","        listMap.append(self.exemplar_sets_labels[el.item()])  #to map to the real classes\n","    \n","      preds=torch.tensor(listMap) #from list to tensor\n","      return preds\n","\n","  def classify_KNN(self, x, train_set,transform,standardize):\n","    self.net.train(False)    \n","    with torch.no_grad():\n","      batch_size = x.size(0)                  #128, batch_size\n","      if self.compute_means:\n","        print(\"Now the features are computed \")\n","        all_labels=[]\n","        all_features = []\n","        count=-1\n","        for P_y in self.exemplar_sets:\n","          count+=1         \n","          classe_giusta=self.exemplar_sets_labels[count]\n","          for ex in P_y:\n","            ex = transform(Image.fromarray(ex)).cuda()\n","            feature = self.net(ex.unsqueeze(0),True)\n","            feature = feature.squeeze()\n","            if standardize== False:\n","              feature.data = feature.data/ feature.data.norm() # Normalize              \n","            all_features.append(feature.tolist())              \n","            all_labels.append(classe_giusta)        \n","          # if classe_giusta in self.new_classes:            \n","          #   img_classes=train_set.get_image_class(classe_giusta)\n","          #   for immagine in img_classes:\n","          #     im = transform(Image.fromarray(immagine)).cuda()\n","          #     feature = self.net(im.unsqueeze(0),True)\n","          #     feature = feature.squeeze()\n","          #     if standardize== False:\n","          #       feature.data = feature.data/ feature.data.norm() # Normalize             \n","          #     all_features.append(feature.tolist())            \n","          #     all_labels.append(classe_giusta)        \n","        self.classifier = KNeighborsClassifier(n_neighbors=5)        \n","        if standardize==True:         \n","          all_features=self.scaler.fit_transform(all_features)\n","        self.classifier.fit(all_features, all_labels)        \n","        self.compute_means = False\n","        print (\"Finish\")        \n","      feature = self.net(x,True)  #tensore[128,64]\n","      feature_to_predict=[]\n","      for i in range(feature.size(0)):\n","        if standardize== False:\n","          feature.data[i] = feature.data[i]/ feature.data[i].norm() #feature.data[i] è un tensore di 64        \n","        lista=feature.data[i].tolist()\n","        feature_to_predict.append(lista)\n","      if standardize==True:\n","        feature_to_predict=self.scaler.transform(feature_to_predict)\n","      preds=self.classifier.predict(feature_to_predict)\n","      preds=torch.tensor(preds) #così return la vera classe non serve mappare\n","      return preds\n","\n","  def classify_LinearSVM(self, x, train_set,transform,standardize):\n","    self.net.train(False)    \n","    with torch.no_grad():\n","      batch_size = x.size(0)                  #128, batch_size\n","      if self.compute_means:\n","        print(\"Now the features are computed \")\n","        all_labels=[]\n","        all_features = []\n","        count=-1\n","        for P_y in self.exemplar_sets:\n","          count+=1         \n","          classe_giusta=self.exemplar_sets_labels[count]\n","          for ex in P_y:\n","            ex = transform(Image.fromarray(ex)).cuda()\n","            feature = self.net(ex.unsqueeze(0),True)\n","            feature = feature.squeeze()\n","            if standardize== False:\n","              feature.data = feature.data/ feature.data.norm() # Normalize              \n","            all_features.append(feature.tolist())              \n","            all_labels.append(classe_giusta)        \n","          # if classe_giusta in self.new_classes:            \n","          #   img_classes=train_set.get_image_class(classe_giusta)\n","          #   for immagine in img_classes:\n","          #     im = transform(Image.fromarray(immagine)).cuda()\n","          #     feature = self.net(im.unsqueeze(0),True)\n","          #     feature = feature.squeeze()\n","          #     if standardize== False:\n","          #       feature.data = feature.data/ feature.data.norm() # Normalize             \n","          #     all_features.append(feature.tolist())            \n","          #     all_labels.append(classe_giusta)        \n","        self.classifier = LinearSVC() \n","        if standardize==True:         \n","          all_features=self.scaler.fit_transform(all_features)\n","        self.classifier.fit(all_features, all_labels)        \n","        self.compute_means = False\n","        print (\"Finish\")        \n","      feature = self.net(x,True)  #tensore[128,64]\n","      feature_to_predict=[]\n","      for i in range(feature.size(0)):\n","        if standardize== False:\n","          feature.data[i] = feature.data[i]/ feature.data[i].norm() #feature.data[i] è un tensore di 64        \n","        lista=feature.data[i].tolist()\n","        feature_to_predict.append(lista)\n","      if standardize==True:\n","        feature_to_predict=self.scaler.transform(feature_to_predict)\n","      preds=self.classifier.predict(feature_to_predict)\n","      preds=torch.tensor(preds) #così return la vera classe non serve mappare\n","      return preds\n","\n","  def classify_Logistic_Regression(self, x, train_set,transform,standardize):\n","    self.net.train(False)    \n","    with torch.no_grad():\n","      batch_size = x.size(0)                  #128, batch_size\n","      if self.compute_means:\n","        print(\"Now the features are computed \")\n","        all_labels=[]\n","        all_features = []\n","        count=-1\n","        for P_y in self.exemplar_sets:\n","          count+=1         \n","          classe_giusta=self.exemplar_sets_labels[count]\n","          for ex in P_y:\n","            ex = transform(Image.fromarray(ex)).cuda()\n","            feature = self.net(ex.unsqueeze(0),True)\n","            feature = feature.squeeze()\n","            if standardize== False:\n","              feature.data = feature.data/ feature.data.norm() # Normalize              \n","            all_features.append(feature.tolist())              \n","            all_labels.append(classe_giusta)        \n","          # if classe_giusta in self.new_classes:            \n","          #   img_classes=train_set.get_image_class(classe_giusta)\n","          #   for immagine in img_classes:\n","          #     im = transform(Image.fromarray(immagine)).cuda()\n","          #     feature = self.net(im.unsqueeze(0),True)\n","          #     feature = feature.squeeze()\n","          #     if standardize== False:\n","          #       feature.data = feature.data/ feature.data.norm() # Normalize             \n","          #     all_features.append(feature.tolist())            \n","          #     all_labels.append(classe_giusta)        \n","        self.classifier = LogisticRegression(max_iter=1000) #solver=lbfgs fa multinomial regression \n","        if standardize==True:         \n","          all_features=self.scaler.fit_transform(all_features)\n","        self.classifier.fit(all_features, all_labels)        \n","        self.compute_means = False\n","        print (\"Finish\")        \n","      feature = self.net(x,True)  #tensore[128,64]\n","      feature_to_predict=[]\n","      for i in range(feature.size(0)):\n","        if standardize== False:\n","          feature.data[i] = feature.data[i]/ feature.data[i].norm() #feature.data[i] è un tensore di 64        \n","        lista=feature.data[i].tolist()\n","        feature_to_predict.append(lista)\n","      if standardize==True:\n","        feature_to_predict=self.scaler.transform(feature_to_predict)\n","      preds=self.classifier.predict(feature_to_predict)\n","      preds=torch.tensor(preds) #così return la vera classe non serve mappare\n","      return preds  \n","\n","  def classify(self, x, train_set,transform):\n","    if self.classifier_variant==\"standard\":\n","      return self.classify_standard(x, train_set,transform)\n","    elif self.classifier_variant==\"KNN\":\n","      return self.classify_KNN(x, train_set,transform,standardize=False)\n","    elif self.classifier_variant==\"Linear_SVM\":\n","      return self.classify_LinearSVM(x, train_set,transform,standardize=False)\n","    elif self.classifier_variant==\"Logistic_Regression\":\n","      return self.classify_Logistic_Regression(x, train_set,transform,standardize=False)\n","    \n","\n","  def increment_classes(self, new_classes):\n","    self.new_classes=[]     #list used to save only the new classes for each step  \n","    for classe in new_classes:  \n","      if classe not in self.classes_known:        #to avoid duplicates\n","        self.classes_known.append(classe)                  \n","        self.n_classes += 1   \n","        self.new_classes.append(classe)\n","    in_features = self.net.fc.in_features                  \n","    out_features = self.net.fc.out_features\n","    weight = self.net.fc.weight.data\n","    bias = self.net.fc.bias.data\n","    self.net.fc = nn.Linear(in_features, out_features+len(self.new_classes), bias=True)\n","    self.net.fc.weight.data[:out_features] = weight   #copy old weights\n","    self.net.fc.bias.data[:out_features] = bias       #copy old biases\n","\n","  def construct_exemplar_set(self,y, images, m, transform): #transform is needed because images are numpy, but we have to pass them through the network to extract the feature vector and so they have to be tensor\n","    self.net.train(False) \n","    with torch.no_grad(): \n","      features = []          #here we save the convolutional layers output of all the images (of the train set) belonging to that class (y) (feature representation)\n","      for img in images:\n","        x = transform(Image.fromarray(img)).cuda()                    #img is a numpy, Image.fromarray(img) is a PIL image, x becomes a tensor\n","        feature = self.net(x.unsqueeze(0),True).data.cpu().numpy()    #feature representation (toExtract=True), unsqueeze is needed because we are passing only one image\n","        feature = feature / np.linalg.norm(feature)                   #normalization\n","        features.append(feature[0])                                   #normalized feature of the image\n","\n","      features = np.array(features)                                 #numpy.array of 500 elements (only images from class y), each of them has len=64 (output size)\n","      class_mean = np.mean(features, axis=0)                        #len=64, compute the class mean\n","      class_mean = class_mean / np.linalg.norm(class_mean)          #normalization\n","        \n","      exemplar_set = []\n","      exemplar_features = []\n","      for k in range(m):        #searching best exemplars\n","        S = np.sum(exemplar_features, axis=0)     #first run shape=0, then it's a numpy.array with 64 elements\n","        phi = features    #numpy with the features of the images, but when an image is chosen as exemplar, it's removed from this array\n","        mu = class_mean\n","        mu_p = 1.0/(k+1) * (phi + S)     #at the beginning [500,64], then [499,64]\n","        mu_p = mu_p / np.linalg.norm(mu_p)   #normalization\n","        i = np.argmin(np.sqrt(np.sum((mu - mu_p) ** 2, axis=1)))   #take the exemplar with the smallest distance from the class mean \n","        exemplar_set.append(images[i])    #save it\n","        exemplar_features.append(features[i]) #save its features representation\n","        features=np.delete(features,i,axis=0) #remove the chosen image (otherwise we waste space with duplicates)\n","      self.exemplar_sets.append(np.array(exemplar_set))      #It's a list in which each element (exemplar_set) is transformed in a numpy.array with length 200 and each element(image) has length 32 (32*32) (because it's a numpy)\n","      self.exemplar_sets_labels.append(y)\n","\n","  def reduce_exemplar_sets(self, m):\n","    for y, P_y in enumerate(self.exemplar_sets):\n","      self.exemplar_sets[y] = P_y[:m]       #select only the first m exemplars (the most important)\n","\n","\n","  def combine_dataset_with_exemplars(self, dataset):\n","    for y, P_y in zip(self.exemplar_sets_labels,self.exemplar_sets):\n","      exemplar_images = P_y #all exemplars of class y\n","      exemplar_labels = [y] * len(P_y)  #to have list containg the real label for all the exemplars belonging to that class\n","      dataset.append(exemplar_images, exemplar_labels)  #now the training set has also the exemplars of the previous classes\n","    # return dataset\n","       \n","  def update_representation(self, dataset):\n","    self.compute_means=True     #since there are new classes the means have to be computed          \n","    \n","    classes = list(set(dataset.targets))      #total distinct labels in the trainig set\n","    self.increment_classes(classes)           #to increment output size of the net, since new classes are added\n","    self.cuda()     \n","    print (f\"Now there are {self.n_classes} classes\")\n","    \n","    optimizer = optim.SGD(self.net.parameters(), lr=self.LR, weight_decay=WEIGHT_DECAY,momentum=MOMENTUM)\n","    scheduler=optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONE, gamma=GAMMA)\n","\n","    self.combine_dataset_with_exemplars(dataset)      #add old exemplars to training set\n","\n","    loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n","\n","    q = torch.zeros(len(dataset), self.n_classes).cuda()  #to initialize q, otherwise q[slice] can't be performed\n","    \n","    for indices, images, labels in loader:\n","      images = images.to(DEVICE)\n","      indices = indices.to(DEVICE)\n","      if self.loss_variant == \"L2_L2\":\n","        g = self.forward(images,False) # sigmoid is not needed if cross entropy loss is used\n","      else:\n","        g = torch.sigmoid(self.forward(images,False))       #sigmoid of outputs of the old network\n","      q[indices] = g.data                                 #save in this way in order to retrieve the correct q for each image when the loss is calculated in the new network\n","      q = q.cuda()\n","\n","    order_label=[]          \n","    for i, (indices, images, labels) in enumerate(loader):\n","      for label in labels:\n","        if label not in self.all_labels:                  #excluding exemplars\n","          if label not in order_label:                    #taking only once the new labels\n","            order_label.append(label)                     \n","            self.dic[label.item()]=self.count_per_dic #construct the dictionary that will be used for mapping the output of the fully connected layer. \n","                                                      #The first class seen will correspond to the output of the first neuron (which is the first column in g) and so on\n","            self.count_per_dic +=1  \n","            self.all_labels.append(label)             #append the new label to the total labels list\n","        \n","    for epoch in range(NUM_EPOCHS):\n","      for i, (indices, images, labels) in enumerate(loader):\n","        indices = indices.cuda()\n","        images = images.cuda()\n","        labels = labels.cuda()\n","\n","        mapped_labels=[]  #map labels of images in the batch, len=batch_size\n","        for label in labels:\n","          mapped_labels.append(self.dic[label.item()])\n","        \n","        oneHot=torch.nn.functional.one_hot(torch.tensor(mapped_labels),self.n_classes)   #return the one hot matrix with\n","                                                                                              #number of columns=self.n_classes\n","                                                                                              #number of rows=number of images in the batch\n","                                                                                              #each row has 1 in the column corresponding to the correct label, 0 otherwise\n","        oneHot=oneHot.type(torch.FloatTensor)   #convert to type float to match with q and g type\n","        oneHot=oneHot.cuda()\n","                \n","        self.net.train()       #start training\n","        optimizer.zero_grad()   #to delete the accumulated gradients\n","        g = self.forward(images)  #scores given by the updated network, (fully connected outputs)\n","        lista_map=[]  #map NEW CLASS, len=10\n","        for classe in self.new_classes:\n","          lista_map.append(self.dic[classe])\n","\n","        old_classes=[item for item in self.classes_known if item not in self.new_classes]\n","        old_classes_mapped=[] #map OLD CLASS, len=10,20,30.....\n","        for classe in old_classes:\n","          old_classes_mapped.append(self.dic[classe])\n","        tot_mapped=old_classes_mapped+lista_map\n","      \n","        if self.loss_variant == \"standard\":\n","          loss=BCEWithLogitsLoss()         #loss used\n","          if len(old_classes) > 0: #classification +distillation (because there are examplars from old classes)\n","            q_i = q[indices]  #retrieve the outputs of the old network     \n","            q_i_class=q_i[:,old_classes_mapped] #columns corresponding to old classes (exemplars)\n","            target = torch.cat((q_i_class, oneHot[:,lista_map]), 1) #concatenate the old outputs of the old network and one hot of new classes (all of them mapped from 0 to num_classes)\n","            loss = loss(g[:,tot_mapped], target)   \n","          else: #only classification\n","            loss=loss(g[:,lista_map],oneHot[:,lista_map])\n","\n","        elif self.loss_variant == \"bce_L2\":\n","          distillation_loss=BCEWithLogitsLoss()\n","          classification_loss=MSELoss()\n","          loss_dist=0.0\n","          #DISTILLATION SOLO SULLE VECCHIE\n","          if len(old_classes) > 0:\n","            q_i = q[indices]\n","            loss_dist = distillation_loss(g[:,old_classes_mapped], q_i[:,old_classes_mapped])\n","          #CLASSIFICATION SOLO SULLE NUOVE\n","          output=g[:,lista_map]\n","          softmax=torch.nn.Softmax(dim=1)\n","          probability=softmax(output)\n","          loss_class=classification_loss(probability,oneHot[:,lista_map])\n","          loss=loss_dist+loss_class\n","\n","        elif self.loss_variant == \"L2_L2\":\n","          distillation_loss=MSELoss()\n","          classification_loss=MSELoss()\n","          loss_dist=0.0\n","          #DISTILLATION SOLO SULLE VECCHIE\n","          if len(old_classes) > 0:\n","            q_i = q[indices]\n","            q_i_old = q_i[:,old_classes_mapped].cuda()\n","            g_sigm=torch.sigmoid(g)\n","            loss_dist = distillation_loss(g_sigm[:,old_classes_mapped], q_i_old)\n","          #CLASSIFICATION SOLO SULLE NUOVE\n","          output=g[:,lista_map]\n","          softmax=torch.nn.Softmax(dim=1)\n","          probability=softmax(output)\n","          loss_class=classification_loss(probability,oneHot[:,lista_map])\n","          loss=loss_dist+loss_class\n","\n","        elif self.loss_variant == \"bce_ce\":\n","          distillation_loss=BCEWithLogitsLoss()\n","          classification_loss=CrossEntropyLoss()\n","          loss_dist=0.0\n","          #DISTILLATION SOLO SULLE VECCHIE\n","          if len(old_classes) > 0:\n","            q_i = q[indices]\n","            loss_dist = distillation_loss(g[:,old_classes_mapped], q_i[:,old_classes_mapped])\n","          #CLASSIFICATION SOLO SULLE NUOVE\n","          output=g  \n","          lista_map_tensore=torch.tensor(mapped_labels).cuda()\n","          loss_class=classification_loss(output,lista_map_tensore)\n","          loss=loss_dist+loss_class\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 10 == 0:\n","          print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}, Iter: {i+1}/{math.ceil(len(dataset)/BATCH_SIZE)}, Loss: {loss.item():.4f}, lr={scheduler.get_last_lr()[0]} \")\n","\n","      scheduler.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOhpAGOD4jxf","colab_type":"text"},"source":["**MAIN**"]},{"cell_type":"code","metadata":{"id":"Ssd9308dFyV-","colab_type":"code","colab":{}},"source":["def give_split():\n","  x=np.arange(0,100)\n","  x=x.tolist()\n","  random.seed(34)\n","  random.shuffle(x)\n","  total_classes=[]\n","  for i in range(0,100,10):\n","    lista=x[i:i+10]\n","    total_classes.append(lista)\n","  return total_classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJSCA6kQdbI4","colab_type":"code","colab":{}},"source":["transform_train = transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n","])\n","\n","transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n","])\n","\n","#to have original version of iCaRL --> loss_variant=\"standard\" && classifier_variant=\"standard\"\n","\n","icarl = iCaRLNet(loss_variant=\"standard\",classifier_variant=\"Linear_SVM\")\n","icarl.cuda()\n","\n","\n","list_classes=give_split()\n","lista_tot=[]\n","\n","list_train_acc=[]\n","list_test_acc=[]\n","\n","for s in range(0,len(list_classes)):\n","  for elem in list_classes[s]:              #creating the list with all the classes seen up to now to create the test set\n","    lista_tot.append(elem)\n","\n","  print(f\"Classes in training set: {list_classes[s]}\")\n","  print(f\"Classes in test set: {lista_tot}\")\n","\n","  train_set = iCIFAR100(root='./data',train=True,classes=list_classes[s],download=True,transform=transform_train)\n","  train_loader = torch.utils.data.DataLoader(train_set, batch_size=128,shuffle=True, num_workers=2)\n","\n","  test_set = iCIFAR100(root='./data',train=False,classes=lista_tot,download=True,transform=transform_test)\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=128,shuffle=False, num_workers=2)\n","\n","  icarl.update_representation(train_set)     # Update network\n","  m = int(K / icarl.n_classes)    #m is maximum number of exemplars for each class\n","\n","  icarl.reduce_exemplar_sets(m)   # Reduce exemplar sets for known classes\n","\n","  for y in icarl.new_classes:   # Construct exemplar sets for new classes\n","    print(f\"Constructing exemplar set for class: {y}\")\n","    images= train_set.get_image_class(y)  #numpy.ndarray of all images of the training set belonging to class y\n","    icarl.construct_exemplar_set(y,images,m, transform_test)  #y=class, images=numpy..., m=number of exemplars to save, transform test because it's needed \n","  print(\"Finish\")\n","\n","  total = 0.0\n","  correct = 0.0\n","  for indices, images, labels in train_loader:\n","    images = images.cuda()    \n","    preds = icarl.classify(images, train_set,transform_test)\n","    total += labels.size(0)\n","    correct += (preds.data.cpu() == labels).sum()\n","    \n","  train_accuracy = correct / total\n","\n","  print(f'Train Accuracy: {train_accuracy}')\n","  list_train_acc.append(train_accuracy)\n","\n","  total = 0.0\n","  correct = 0.0\n","  for indices, images, labels in test_loader:\n","    images = images.cuda()\n","    preds = icarl.classify(images, train_set,transform_test)\n","    total += labels.size(0)\n","    correct += (preds.data.cpu() == labels).sum()\n","    \n","  test_accuracy = correct / total\n","\n","  print(f'Test Accuracy: {test_accuracy}')\n","  list_test_acc.append(test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8D_7btwmMMxS","colab_type":"code","colab":{}},"source":["f = open(\"acc_train.txt\", \"w\")\n","for el in list_train_acc:\n","  f.write(str(el)+\"\\n\")\n","f.close()\n","\n","f = open(\"acc_test.txt\", \"w\")\n","for el in list_test_acc:\n","  f.write(str(el)+\"\\n\")\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8g33nI6k7cGe","colab_type":"text"},"source":["**CONFUSION MATRIX**"]},{"cell_type":"code","metadata":{"id":"40czvCyIJhgi","colab_type":"code","colab":{}},"source":["@torch.no_grad()\n","def get_all_preds(model, loader):\n","  all_preds = torch.tensor([])\n","  for indices, images, labels in loader:\n","    images = images.cuda()\n","    preds = icarl.classify(images,train_set,transform_test).to(torch.float32)\n","    # print(preds)\n","    # print(type(all_preds[0]))\n","    # preds = model(images, False) #?????? FALSE\n","    preds = preds.cuda()\n","    # print(preds)\n","    all_preds = torch.cat((all_preds.cuda(), preds), dim=0) #Concatenates the given sequence of seq tensors in the given dimension. \n","                              #All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n","                              #dim (int, optional) – the dimension over which the tensors are concatenated\n","  \n","  all_preds = all_preds.tolist()\n","  return all_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7r3DFN06WJH","colab_type":"code","colab":{}},"source":["test_set = iCIFAR100(root='./data', train=False, classes=range(100), download=True, transform=transform_test)\n","with torch.no_grad():\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","  test_preds = get_all_preds(icarl, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQ6XCoGp9VmT","colab_type":"code","colab":{}},"source":["cm = confusion_matrix(test_set.targets, test_preds, labels=lista_tot)\n","print(type(cm))\n","cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1ATfMF--vvK","colab_type":"code","colab":{}},"source":["def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.jet):\n","  if normalize:\n","        # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    ones = np.ones(cm.shape)\n","    t = ones + cm\n","    cm = np.log(t)\n","        # ones = torch.ones(cm.shape, dtype=torch.float32)\n","        # cm = torch.log()\n","    print(\"Normalized confusion matrix\")\n","  else:\n","    print('Confusion matrix, without normalization')\n","\n","  # print(cm)\n","  plt.figure(figsize=(10,10))\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  # plt.title(title)\n","  # plt.colorbar()\n","    # tick_marks = np.arange(len(classes))\n","    # plt.xticks(tick_marks, classes, rotation=45)\n","    # plt.yticks(tick_marks, classes)\n","\n","    # fmt = '.2f' if normalize else 'd'\n","    # thresh = cm.max() / 2.\n","    # for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        # plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  if normalize==True:\n","    plt.savefig(\"Confusion matrix Normalize\")\n","  else:\n","    plt.savefig(\"Confusion matrix NOT Normalize\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEZVm7M2AJR0","colab_type":"code","colab":{}},"source":["plot_confusion_matrix(cm, test_set.classes, normalize=True)"],"execution_count":null,"outputs":[]}]}