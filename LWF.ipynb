{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LWF.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X9pJaGMHvUTf","colab_type":"text"},"source":["**MODULES**"]},{"cell_type":"code","metadata":{"id":"HpCwBfycvTB5","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import BCEWithLogitsLoss\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","from torchvision.datasets import CIFAR100\n","import torch.optim as optim\n","\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import random\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_-0s4GMitVt","colab_type":"text"},"source":["**ICIFAR100**"]},{"cell_type":"code","metadata":{"id":"LhEvvapHQW62","colab_type":"code","colab":{}},"source":["class iCIFAR10(CIFAR10):\n","  def __init__(self, root,classes,train,transform=None,target_transform=None,download=False):\n","    super(iCIFAR10, self).__init__(root,train=train,transform=transform,target_transform=target_transform,download=download)\n","    \n","    train_data = []\n","    train_labels = []\n","\n","    for i in range(len(self.data)):\n","      if self.targets[i] in classes:\n","        train_data.append(self.data[i])\n","        train_labels.append(self.targets[i])\n","\n","    self.data = np.array(train_data)\n","    self.targets = train_labels\n","  \n","  def __getitem__(self, index):\n","    img, target = self.data[index], self.targets[index]\n","    img = Image.fromarray(img)\n","    \n","    if self.transform is not None:\n","      img = self.transform(img)\n","    \n","    if self.target_transform is not None:\n","      target = self.target_transform(target)\n","    \n","    return index, img, target\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def get_image_class(self, label):\n","    return self.data[np.array(self.targets) == label]\n","\n","  def append(self, images, labels):\n","    self.data = np.concatenate((self.data, images), axis=0)\n","    self.targets = self.targets + labels\n","\n","class iCIFAR100(iCIFAR10):\n","    base_folder = 'cifar-100-python'\n","    url = \"http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n","    filename = \"cifar-100-python.tar.gz\"\n","    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n","    train_list = [\n","        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n","    ]\n","    test_list = [\n","        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n","    ]\n","    meta = {\n","        'filename': 'meta',\n","        'key': 'fine_label_names',\n","        'md5': '7973b15100ade9c7d40fb424638fde48',\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QAC9q4Sr4zfI","colab_type":"text"},"source":["**MODEL**"]},{"cell_type":"code","metadata":{"id":"zKkdgE9sitA6","colab_type":"code","colab":{}},"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=0): #SAREBBE num_classes=10\n","        self.inplanes = 16\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_layer(block, 16, layers[0])\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        self.fc = nn.Linear(64 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, toExtract):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        if toExtract==True:\n","          return x\n","        else:\n","          x = self.fc(x)\n","          return x\n","\n","def resnet32(pretrained=False, **kwargs):\n","    n = 5\n","    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38vFYaZtoNIQ","colab_type":"text"},"source":["**Set Argument**"]},{"cell_type":"code","metadata":{"id":"wHjF3m9On4J5","colab_type":"code","colab":{}},"source":["DEVICE = 'cuda'    \n","BATCH_SIZE = 128\n","LR = 2         \n","NUM_EPOCHS = 70\n","MILESTONE=[49,63]\n","WEIGHT_DECAY = 0.00001 \n","GAMMA = 0.2\n","MOMENTUM=0.9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_NQKsDRlAiV","colab_type":"code","colab":{}},"source":["class iCaRLNet(nn.Module):\n","  def __init__(self):\n","    super(iCaRLNet, self).__init__()\n","    self.net = resnet32()        \n","    self.n_classes = 0\n","    self.n_known = 0\n","    self.classes_known=[]\n","    self.new_classes=[]\n","    self.dic={}\n","    self.count_per_dic=0\n","    \n","    self.loss=BCEWithLogitsLoss()\n","    \n","  def forward(self, x, toExtract=False):\n","    x = self.net(x, toExtract)\n","    return x\n","\n","  @torch.no_grad()\n","  def classify(self,images):\n","    self.net.train(False)\n","    _, preds=torch.max(self.forward(images,False), dim=1)\n","    mapped=[]\n","    for pred in preds:\n","      mapped.append(list(self.dic.keys())[list(self.dic.values()).index(pred.item())]) \n","    tensore=torch.tensor(mapped)\n","    return tensore\n","\n","  def increment_classes(self, new_classes):\n","    self.new_classes=[]  \n","    for classe in new_classes:\n","      if classe not in self.classes_known:\n","        self.classes_known.append(classe)\n","        self.n_classes += 1\n","        self.new_classes.append(classe)\n","    in_features = self.net.fc.in_features\n","    out_features = self.net.fc.out_features\n","    weight = self.net.fc.weight.data\n","    bias = self.net.fc.bias.data\n","    self.net.fc = nn.Linear(in_features, out_features+len(self.new_classes), bias=True)\n","    self.net.fc.weight.data[:out_features] = weight\n","    self.net.fc.bias.data[:out_features] = bias    \n","          \n","  def update_representation(self, dataset):\n","    \n","    classes = list(set(dataset.targets))\n","    self.increment_classes(classes)\n","    self.cuda()\n","    print (\"Now there are %d classes\" % (self.n_classes))\n","    \n","    optimizer = optim.SGD(self.net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n","    scheduler=optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONE, gamma=GAMMA)\n","\n","    loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n","\n","    q = torch.zeros(len(dataset), self.n_classes).cuda()\n","    for indices, images, labels in loader:\n","      images = images.to(DEVICE)\n","      indices = indices.to(DEVICE)\n","      g = torch.sigmoid(self.forward(images,False))\n","      q[indices] = g.detach()\n","      q = q.cuda()\n","\n","\n","    order_label=[]\n","    for i, (indices, images, labels) in enumerate(loader):\n","      for label in labels:\n","        if label not in order_label:\n","          order_label.append(label)      \n","          self.dic[label.item()]=self.count_per_dic\n","          self.count_per_dic +=1\n","\n","    for epoch in range(NUM_EPOCHS):\n","      for i, (indices, images, labels) in enumerate(loader):\n","        indices = indices.cuda()\n","        images = images.cuda()\n","        labels = labels.cuda()\n","\n","        mapped_labels=[]\n","        for label in labels:\n","          mapped_labels.append(self.dic[label.item()])\n","\n","\n","        oneHot=torch.nn.functional.one_hot(torch.tensor(mapped_labels),self.n_classes)\n","        oneHot=oneHot.type(torch.FloatTensor)\n","        oneHot=oneHot.cuda()\n","                \n","        self.net.train()\n","        optimizer.zero_grad()\n","        g = self.forward(images)\n","        lista_map=[]\n","        for classe in self.new_classes:\n","          lista_map.append(self.dic[classe])\n","\n","        old_classes=[item for item in self.classes_known if item not in self.new_classes]\n","        old_classes_mapped=[]\n","        for classe in old_classes:\n","          old_classes_mapped.append(self.dic[classe])\n","        tot_mapped=old_classes_mapped+lista_map\n","      \n","        if len(old_classes) > 0:\n","          q_i = q[indices]\n","          q_i_class=q_i[:,old_classes_mapped]\n","          target = torch.cat((q_i_class, oneHot[:,lista_map]), 1)\n","          loss = self.loss(g[:,tot_mapped], target)\n","        else:\n","          loss=self.loss(g[:,lista_map],oneHot[:,lista_map])\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 10 == 0:\n","          print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}, Iter: {i+1}/{math.ceil(len(dataset)/BATCH_SIZE)}, Loss: {loss.item():.4f}, lr={scheduler.get_last_lr()[0]} \")\n","      scheduler.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOhpAGOD4jxf","colab_type":"text"},"source":["**MAIN**"]},{"cell_type":"code","metadata":{"id":"Ssd9308dFyV-","colab_type":"code","colab":{}},"source":["def give_split():\n","  x=np.arange(0,100)\n","  x=x.tolist()\n","  random.seed(34)\n","  random.shuffle(x)\n","  total_classes=[]\n","  for i in range(0,100,10):\n","    lista=x[i:i+10]\n","    total_classes.append(lista)\n","  return total_classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJSCA6kQdbI4","colab_type":"code","colab":{}},"source":["\n","\n","transform_train = transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n","])\n","\n","transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n","])\n","\n","icarl = iCaRLNet()\n","icarl.cuda()\n","\n","\n","list_classes=give_split()\n","lista_tot=[]\n","\n","list_train_acc=[]\n","list_test_acc=[]\n","\n","for s in range(0,len(list_classes)):\n","  for elem in list_classes[s]:\n","    lista_tot.append(elem)\n","  print(\"Loading training examples for classes\", list_classes[s])\n","\n","  print(f\"In train {list_classes[s]}\")\n","  print(f\"In test {lista_tot}\")\n","  train_set = iCIFAR100(root='./data',train=True,classes=list_classes[s],download=True,transform=transform_train)\n","  train_loader = torch.utils.data.DataLoader(train_set, batch_size=128,shuffle=True, num_workers=2)\n","\n","  test_set = iCIFAR100(root='./data',train=False,classes=lista_tot,download=True,transform=transform_test)\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=128,shuffle=False, num_workers=2)\n","\n","  icarl.update_representation(train_set)\n","\n","\n","  icarl.n_known = icarl.n_classes\n","\n","\n","  icarl.net.train(False)\n","  total = 0.0\n","  correct = 0.0\n","  for indices, images, labels in train_loader:\n","    images = images.to(DEVICE)\n","    labels = labels.to(DEVICE)\n","\n","\n","    preds = icarl.classify(images).to(DEVICE)\n","    correct += torch.sum(preds == labels.data).data.item()\n","    total += labels.size(0)\n","\n","\n","  train_accuracy = correct / total\n","  print(f'Train Accuracy: {train_accuracy}')\n","  list_train_acc.append(train_accuracy)\n","\n","  total = 0.0\n","  correct = 0.0\n","  for indices, images, labels in test_loader:\n","    images = images.to(DEVICE)\n","    labels = labels.to(DEVICE)\n","\n","    preds = icarl.classify(images).to(DEVICE)\n","    \n","    correct += torch.sum(preds == labels.data).data.item()\n","    total += labels.size(0)\n","\n","  test_accuracy = correct / total\n","  print(f'Test Accuracy: {test_accuracy}')\n","  list_test_acc.append(test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8D_7btwmMMxS","colab_type":"code","colab":{}},"source":["f = open(\"acc_train.txt\", \"w\")\n","for el in list_train_acc:\n","  f.write(str(el)+\"\\n\")\n","f.close()\n","\n","f = open(\"acc_test.txt\", \"w\")\n","for el in list_test_acc:\n","  f.write(str(el)+\"\\n\")\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8g33nI6k7cGe","colab_type":"text"},"source":["**CONFUSION MATRIX**"]},{"cell_type":"code","metadata":{"id":"40czvCyIJhgi","colab_type":"code","colab":{}},"source":["@torch.no_grad()\n","def get_all_preds(model, loader):\n","  all_preds = torch.tensor([])\n","  for indices, images, labels in loader:\n","    images = images.cuda()\n","    preds = icarl.classify(images).to(torch.float32)\n","    # print(preds)\n","    # print(type(all_preds[0]))\n","    # preds = model(images, False) #?????? FALSE\n","    preds = preds.cuda()\n","    # print(preds)\n","    all_preds = torch.cat((all_preds.cuda(), preds), dim=0) #Concatenates the given sequence of seq tensors in the given dimension. \n","                              #All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n","                              #dim (int, optional) – the dimension over which the tensors are concatenated\n","  \n","  all_preds = all_preds.tolist()\n","  return all_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7r3DFN06WJH","colab_type":"code","colab":{}},"source":["test_set = iCIFAR100(root='./data', train=False, classes=range(100), download=True, transform=transform_test)\n","with torch.no_grad():\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","  test_preds = get_all_preds(icarl, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQ6XCoGp9VmT","colab_type":"code","colab":{}},"source":["cm = confusion_matrix(test_set.targets, test_preds, labels=lista_tot)\n","print(type(cm))\n","cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1ATfMF--vvK","colab_type":"code","colab":{}},"source":["def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.jet):\n","  if normalize:\n","        # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    ones = np.ones(cm.shape)\n","    t = ones + cm\n","    cm = np.log(t)\n","        # ones = torch.ones(cm.shape, dtype=torch.float32)\n","        # cm = torch.log()\n","    print(\"Normalized confusion matrix\")\n","  else:\n","    print('Confusion matrix, without normalization')\n","\n","  # print(cm)\n","  plt.figure(figsize=(10,10))\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  #plt.title(title)\n","  #plt.colorbar()\n","    # tick_marks = np.arange(len(classes))\n","    # plt.xticks(tick_marks, classes, rotation=45)\n","    # plt.yticks(tick_marks, classes)\n","\n","    # fmt = '.2f' if normalize else 'd'\n","    # thresh = cm.max() / 2.\n","    # for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        # plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  if normalize==True:\n","    plt.savefig(\"Confusion matrix Normalize\")\n","  else:\n","    plt.savefig(\"Confusion matrix NOT Normalize\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEZVm7M2AJR0","colab_type":"code","colab":{}},"source":["plot_confusion_matrix(cm, test_set.classes, normalize=True)"],"execution_count":null,"outputs":[]}]}